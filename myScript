
#!/usr/bin/env python
# vim:fileencoding=utf-8
from calibre.web.feeds.news import BasicNewsRecipe

class AdvancedUserRecipe(BasicNewsRecipe):
    title          = '全职国医'
    # 抓取页面内容设置
    #///////////////////
    #keep_only_tags = [dict(id=['content', 'list']),dict(name='div', class_='bookname')] # 仅保留指定选择器包含的内容
    no_stylesheets = True # 去除 CSS 样式
    remove_javascript = True # 去除 JavaScript 脚本
    auto_cleanup = True # 自动清理 HTML 代码
    max_articles_per_feed = 9999 # 抓取文章数量
    simultaneous_downloads = 20
    #remove_tags = [dict(name='br')]
    #解析内容方法
    
    #///////////////////
    # 页面列表解析方法
    #///////////////////
    def parse_index(self):
        orin = 'https://www.xbiquge.la'
        site = 'https://www.xbiquge.la/36/36328/' # 页面列表页
        soup = self.index_to_soup(site) # 解析列表页返回 BeautifulSoup 对象
        links = soup.find(id='list').find_all('a') # 获取所有文章链接
        articles = [] # 定义空文章资源数组
        for link in links: # 循环处理所有文章链接
            title = link.contents[0].strip() # 提取文章标题
            url = orin + link.get("href") # 提取文章链接
            a = {'title': title , 'url':url} # 组合标题和链接
            articles.append(a) # 累加到数组中
        ans = [(self.title, articles)] # 组成最终的数据结构
        return ans # 返回可供 Calibre 转换的数据结构
    def preprocess_raw_html(self, raw_html, url):
        soup = BeautifulSoup(raw_html)
        title = soup.find('h1').string

        content = soup.find(id='content')
        a = content.find('a')
        a.clear()
        p = a.find_previous('p')
        p.clear()
    
        from lxml.html import document_fromstring, fragment_fromstring, tostring
        root = document_fromstring(
                '<html><head><title>%s</title></head><body>%s<body/></html>' %(title,content))
        raw_html = tostring(root, encoding='unicode')
        #print("html:",html)
        return raw_html
